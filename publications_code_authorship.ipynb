{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from crossref.restful import Works\n",
    "works = Works()\n",
    "\n",
    "def get_match(author, staff, min_score=75):\n",
    "    m = process.extract(author, staff,\n",
    "                        scorer=fuzz.token_sort_ratio)\n",
    "    m = [item for item in m if item[1] > min_score]\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pubs 493\n",
      "Number of staff before dropping dupes 137\n",
      "Number of staff after dropping dupes 137\n"
     ]
    }
   ],
   "source": [
    "staff = pd.read_excel(\"MCS_Author_Names.xlsx\", skiprows=3)\n",
    "pubs = pd.read_excel(\"MCS_publications_20220401.xlsx\", sheet_name='query')\n",
    "print('Number of pubs {}'.format(len(pubs)))\n",
    "# How many staff?\n",
    "print('Number of staff before dropping dupes {}'.format(len(staff)))\n",
    "staff = staff.drop_duplicates()\n",
    "print('Number of staff after dropping dupes {}'.format(len(staff)))\n",
    "staff = pd.wide_to_long(staff, 'Variant', i='Name', j='Variant_Number', sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493\n",
      "Index(['Title', 'CI Author', 'Publication', 'Publication Date', 'DOI',\n",
      "       'Modified', 'Fiscal Year', 'Publication Status', 'Name',\n",
      "       'Contains/Mentions Data From Indonesia',\n",
      "       'Does this study have spatial outputs?', 'URL to spatial data',\n",
      "       'Item Type', 'Path'],\n",
      "      dtype='object')\n",
      "Fiscal Year\n",
      "126;#FY08     4\n",
      "177;#FY18    35\n",
      "190;#FY07     1\n",
      "191;#FY20    52\n",
      "196;#FY06     5\n",
      "197;#FY05     2\n",
      "199;#FY00     3\n",
      "206;#FY19    51\n",
      "242;#FY03     1\n",
      "249;#FY02     2\n",
      "253;#FY21    43\n",
      "268;#FY22    27\n",
      "62;#FY16     47\n",
      "63;#FY15     16\n",
      "70;#FY17     49\n",
      "81;#FY11     45\n",
      "85;#FY12     25\n",
      "93;#FY14      9\n",
      "94;#FY09     17\n",
      "97;#FY13      7\n",
      "99;#FY10     30\n",
      "Name: Fiscal Year, dtype: int64\n",
      "423\n",
      "417\n"
     ]
    }
   ],
   "source": [
    "# How many pubs?\n",
    "print(len(pubs))\n",
    "\n",
    "print(pubs.columns)\n",
    "print(pubs.groupby(['Fiscal Year'])['Fiscal Year'].count())\n",
    "\n",
    "# How many missing DOIs?\n",
    "dois = pubs.DOI.dropna()\n",
    "print((len(dois)))\n",
    "dois = dois.drop_duplicates()\n",
    "\n",
    "# How many remaining dois?\n",
    "print((len(dois)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['indexed', 'reference-count', 'publisher', 'license', 'funder', 'content-domain', 'short-container-title', 'published-print', 'DOI', 'type', 'created', 'page', 'update-policy', 'source', 'is-referenced-by-count', 'title', 'prefix', 'volume', 'author', 'member', 'reference', 'container-title', 'original-title', 'language', 'link', 'deposited', 'score', 'subtitle', 'short-title', 'issued', 'references-count', 'alternative-id', 'URL', 'relation', 'ISSN', 'issn-type', 'subject', 'assertion'])\n"
     ]
    }
   ],
   "source": [
    "w = works.doi('10.1016/j.forpol.2018.08.002')\n",
    "print(w.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [401]>\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3ade40a70bf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://api.altmetric.com/v1/doi/{}?key={}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maltmetrics_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\mcs-pubs\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    898\u001b[0m                     \u001b[1;31m# used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 900\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\mcs-pubs\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\mcs-pubs\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\mcs-pubs\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "altmetrics_key = '3372dd4fc4d9473c96543743c404e0ca'\n",
    "doi = '10.1016/j.forpol.2018.08.002'\n",
    "resp = requests.get('https://api.altmetric.com/v1/doi/{}?key={}'.format(doi, altmetrics_key))\n",
    "print(resp)\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n",
      "[{'given': 'Matthew', 'family': 'Cooper', 'sequence': 'first', 'affiliation': []}, {'ORCID': 'http://orcid.org/0000-0002-6008-4918', 'authenticated-orcid': False, 'given': 'Alex', 'family': 'Zvoleff', 'sequence': 'additional', 'affiliation': []}, {'given': 'Mariano', 'family': 'Gonzalez-Roglich', 'sequence': 'additional', 'affiliation': []}, {'given': 'Felly', 'family': 'Tusiime', 'sequence': 'additional', 'affiliation': []}, {'given': 'Mark', 'family': 'Musumba', 'sequence': 'additional', 'affiliation': []}, {'given': 'Monica', 'family': 'Noon', 'sequence': 'additional', 'affiliation': []}, {'given': 'Peter', 'family': 'Alele', 'sequence': 'additional', 'affiliation': []}, {'given': 'Madeleine', 'family': 'Nyiratuza', 'sequence': 'additional', 'affiliation': []}]\n",
      "Geographic factors predict wild food and nonfood NTFP collection by households across four African countries\n"
     ]
    }
   ],
   "source": [
    "journal = w['container-title'][0]\n",
    "title = w['title'][0]\n",
    "date = datetime.datetime.fromisoformat(w['created']['date-time'].rstrip('Z'))\n",
    "print(date.year)\n",
    "print(w['author'])\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sidewall'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ab5567f41d97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msidewall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msidewall\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sidewall'"
     ]
    }
   ],
   "source": [
    "import sidewall\n",
    "from sidewall import dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>Unhandled Exception</title>\n",
      "</head><body>\n",
      "<h1>Unhandled Exception</h1>\n",
      "<p>An unhandled exception was thrown by the application.</p>\n",
      "</body></html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citations = requests.post('https://w3id.org/oc/index/api/v1/coauthorship/{}'.format('10.1016/j.forpol.2018.08.002'))\n",
    "print(citations.text)\n",
    "#citation_count = requests.post('https://w3id.org/oc/index/api/v1/citation-count/{}'.format('10.1016/j.forpol.2018.08.002'))\n",
    "#print(citation_count.json()[0]['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 10.17159/2222-3436/2016/v19n5a2, not on crossref\n",
      "Skipping 10.1126/science.aau2650, not on crossref\n",
      "Skipping 10.5281/zenodo.1463063, not on crossref\n",
      "Skipping 10.5281/zenodo.3386441, not on crossref\n",
      "Skipping https://doi.org/10.1007/s00267- 021-01446-1, not on crossref\n",
      "Skipping 10.2305/IUCN.CH.2021.PARKS‐27‐1HJ.en, not on crossref\n",
      "Skipping https://doi.org/10.1016/j.gloenvcha.2021.1023680959-3780, not on crossref\n",
      "Skipping https://doi.org/10.1007/s13280- 021-01628-5., not on crossref\n"
     ]
    }
   ],
   "source": [
    "out = pd.DataFrame(columns=(\"DOI\", \"Journal\", \"Year\", \"Title\", \"Pub_Author\", \"Matched_Author\", \"Author_Position\", \"Total_Authors\", \"Citations\"))\n",
    "skips = pd.DataFrame(columns=(\"DOI\", \"Reason\"))\n",
    "all_w = []\n",
    "for doi in dois:\n",
    "    w = works.doi(doi)\n",
    "    if w is None:\n",
    "        print('Skipping {}, not on crossref'.format(doi))\n",
    "        continue\n",
    "    citation_resp = requests.post('https://w3id.org/oc/index/api/v1/citation-count/{}'.format(doi))\n",
    "    if citation_resp:\n",
    "        w['citation_resp'] = citation_resp.json()\n",
    "    else:\n",
    "        w['citation_resp'] = None\n",
    "    all_w.append(w)\n",
    "with open('publications_raw.json', 'w') as outfile:\n",
    "    json.dump(all_w, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('publications_raw.json', 'r') as f:\n",
    "    all_w = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping author on 10.1371/journal.pone.0121040, full author information not on crossref for {'name': 'The PLOS ONE Staff', 'sequence': 'first', 'affiliation': []}\n",
      "Skipping author on 10.1073/pnas.1714977115, full author information not on crossref for {'family': 'Onrizal', 'sequence': 'additional', 'affiliation': [{'name': 'Faculty of Forestry, Universitas Sumatera Utara, Medan 20155, Indonesia;'}]}\n",
      "Skipping author on 10.1073/pnas.1714977115, full author information not on crossref for {'family': 'Supriyadi', 'sequence': 'additional', 'affiliation': [{'name': 'Faculty of Forestry, Universitas Gadjah Mada, Yogyakarta 55281, Indonesia;'}]}\n",
      "Skipping 10.1111/j.1523-1739.2009.01300.x, no author information on crossref\n",
      "Skipping author on 10.1016/j.biocon.2020.108849, full author information not on crossref for {'family': 'ForestPlots.net', 'sequence': 'first', 'affiliation': []}\n"
     ]
    }
   ],
   "source": [
    "pub_list = pd.DataFrame(columns=(\"DOI\",\n",
    "                                 \"Journal\",\n",
    "                                 \"Year\",\n",
    "                                 \"Title\",\n",
    "                                 \"Pub_Author\",\n",
    "                                 \"Matched_Author\",\n",
    "                                 \"Author_Position\",\n",
    "                                 \"Total_Authors\",\n",
    "                                 \"Citations\"))\n",
    "coauthors = {}\n",
    "coauthor_institutions = {}\n",
    "skips = pd.DataFrame(columns=(\"DOI\", \"Reason\"))\n",
    "for w in all_w:\n",
    "    try:\n",
    "        authors = w['author']\n",
    "        journal = w.get('container-title', None)\n",
    "        if isinstance(journal, list) and len(journal) > 0:\n",
    "            journal = journal[0]\n",
    "        title = w.get('title', None)\n",
    "        if isinstance(title, list) and len(title) > 0:\n",
    "            title = title[0]\n",
    "        year = datetime.datetime.fromisoformat(w['created']['date-time'].rstrip('Z')).year\n",
    "    except KeyError:\n",
    "        print('Skipping {}, no author information on crossref'.format(w['DOI']))\n",
    "        skips.loc[len(skips) + 1] = [w['DOI'], 'missing fields on crossref']\n",
    "        continue\n",
    "    if w['citation_resp']:\n",
    "        citation_count = w['citation_resp'][0]['count']\n",
    "    else:\n",
    "        citation_count = None\n",
    "    authors_cleaned = []\n",
    "    for n in range(len(authors)):\n",
    "        try:\n",
    "            author = '{} {}'.format(authors[n]['given'], authors[n]['family'])\n",
    "        except KeyError:\n",
    "            print('Skipping author on {}, full author information not on crossref for {}'.format(w['DOI'], authors[n]))\n",
    "            skips.loc[len(skips) + 1] = [w['DOI'], 'full author information not on crossref for {}'.format(w['DOI'], authors[n])]\n",
    "            continue\n",
    "        authors_cleaned.append((author, n))\n",
    "    for author, position in authors_cleaned:\n",
    "        #Take the first match - should be best match, so improve this\n",
    "        m = get_match(author, staff['Variant'])\n",
    "        if len(m) > 0:\n",
    "            m = m[0]\n",
    "            staff_name = staff.index[staff['Variant'] == m[0]][0][0]\n",
    "            pub_list.loc[len(pub_list) + 1] = [w['DOI'], journal, year, title, author, staff_name, position + 1, len(authors), citation_count]\n",
    "            if staff_name in coauthors.keys():\n",
    "                if year in coauthors[staff_name].keys():\n",
    "                    for a in authors_cleaned:\n",
    "                        coauthors[staff_name][year].add(a)\n",
    "                else:\n",
    "                    coauthors[staff_name][year] = set(authors_cleaned)\n",
    "            else:\n",
    "                coauthors[staff_name] = {year: set(authors_cleaned)}\n",
    "            # Don't list people as coauthors of themselves...\n",
    "            coauthors[staff_name][year].remove((author, position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_list['Authorship_Type'] = 'Other'\n",
    "pub_list['Authorship_Type'][pub_list['Author_Position'] == 1] = 'First'\n",
    "pub_list['Authorship_Type'][pub_list['Author_Position'] == 2] = 'Second'\n",
    "pub_list['Authorship_Type'][(pub_list['Total_Authors'] > 3) & (pub_list['Author_Position'] == pub_list['Total_Authors'])] = 'Senior'\n",
    "pub_list.to_csv('MCS_publications_author_order.csv', index=False)\n",
    "skips.to_csv('MCS_publications_skipped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make adjacency matrix for network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long format\n",
    "edges = []\n",
    "for author, year in coauthors.items():\n",
    "    for year, coauthors_by_year in year.items():\n",
    "        for coauthor in coauthors_by_year:\n",
    "            edges.append((author, year, coauthor))\n",
    "\n",
    "df = pd.DataFrame(edges, columns=('CI_Author', 'Year', 'Coauthor'))\n",
    "df.to_csv('MCS_publications_coauthor_matrix_long.csv', index=False)\n",
    "\n",
    "# Wide format\n",
    "edges_wide = [(a, b) for a, bs in coauthors.items() for b in bs]\n",
    "df_wide = pd.DataFrame(edges_wide)\n",
    "adj_matrix = pd.crosstab(df_wide[0], df_wide[1])\n",
    "adj_matrix.to_csv('MCS_publications_coauthor_matrix_wide.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Donatti, Camila', 2016, ('Jason P. Landrum', 12))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "gee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
